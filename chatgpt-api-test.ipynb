{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: requests in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (4.66.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\w513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib requests tqdm openpyxl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic configuration for logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def load_config():\n",
    "    try:\n",
    "        with open('config-chatgpt.json', 'r') as config_file:\n",
    "            config = json.load(config_file)\n",
    "        check_api_key(config['openai_api_key'])  # Call to validate API key\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        logging.error(\"Configuration file 'config-chatgpt.json' not found.\")\n",
    "        raise FileNotFoundError(\"Configuration file 'config-chatgpt.json' not found.\")\n",
    "    except KeyError:\n",
    "        logging.error(\"API key not found in configuration.\")\n",
    "        raise KeyError(\"API key not found in configuration file.\")\n",
    "    \n",
    "def check_api_key(api_key):\n",
    "    \"\"\" Check if the OpenAI API key is valid \"\"\"\n",
    "    url = \"https://api.openai.com/v1/engines\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    response = requests.get(url, headers=headers, verify=False)\n",
    "    if response.status_code == 200:\n",
    "        logging.info(\"API key is valid.\")\n",
    "    else:\n",
    "        logging.error(f\"API key is not valid. Status code: {response.status_code}\")\n",
    "        raise ValueError(f\"API key is not valid. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "def load_users(filename):\n",
    "    return pd.read_excel(filename)\n",
    "\n",
    "def load_questions(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def send_question(user, question):\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {config['openai_api_key']}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    }\n",
    "    start = time.time()\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers, verify=False)\n",
    "        response.raise_for_status() # This will raise an HTTPError for HTTP error responses\n",
    "        return {\"time\": time.time() - start, \"data\": response.json(), \"error\": None}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error sending question for user {user['name']}: {e}\")\n",
    "        return {\"time\": time.time() - start, \"data\": None, \"error\": str(e)}\n",
    "\n",
    "def run_test():\n",
    "    users = load_users(config[\"user_file\"])\n",
    "    questions = load_questions(config[\"question_file\"])\n",
    "    total_response_times = []\n",
    "    total_errors = []\n",
    "\n",
    "    for index, user in enumerate(tqdm(users.iterrows(), desc=\"Processing users\"), start=1):\n",
    "        user_data = user[1]\n",
    "        user_response_times = []\n",
    "        success_count = 0\n",
    "        error_count = 0\n",
    "\n",
    "        for question in questions:\n",
    "            result = send_question(user_data, question)\n",
    "            user_response_times.append(result[\"time\"])\n",
    "            if result[\"error\"]:\n",
    "                error_count += 1\n",
    "                logging.info(f\"User {user_data['name']} asked: '{question}', error: {result['error']}\")\n",
    "            else:\n",
    "                success_count += 1\n",
    "                logging.info(f\"User {user_data['name']} asked: '{question}', received: {result['data'].get('choices', [{}])[0].get('message', {}).get('content')}\")\n",
    "\n",
    "        total_response_times.append(user_response_times)\n",
    "        total_errors.append((success_count, error_count))\n",
    "        plot_user_response_times(user_data, user_response_times, success_count, error_count)\n",
    "\n",
    "    plot_response_times_across_users(total_response_times)\n",
    "\n",
    "'''\n",
    "The first plot is a histogram of response times for a specific user. \n",
    "The y-axis label 'Frequency' makes sense here as histograms typically display frequency distributions.\n",
    "\n",
    "The second plot is a bar chart showing the number of successes and errors for the same user. \n",
    "The y-axis label 'Count' is appropriate here as we're counting the number of successes and errors.\n",
    "'''\n",
    "\n",
    "def plot_user_response_times(user_data, response_times, success_count, error_count):\n",
    "    # Create a figure and two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))  # 1 row, 2 columns\n",
    "\n",
    "    # First plot: Response Times Distribution\n",
    "    ax1.hist(response_times, bins=20, alpha=0.75, color='tab:blue')\n",
    "    ax1.set_title(f\"Response Times Distribution for {user_data['name']}\")\n",
    "    ax1.set_xlabel('Response Time (s)')\n",
    "    ax1.set_ylabel('Response Count per Interval')  # Updated label for clarity\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Second plot: Success/Error Counts\n",
    "    ax2.bar(['Successes', 'Errors'], [success_count, error_count], color=['green', 'red'])\n",
    "    ax2.set_title(f'Success/Error Counts for {user_data[\"name\"]}')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_ylim(0, max(success_count, error_count) + 1)  # Adjust y limit to ensure bars are fully visible\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout so that both plots are neatly arranged\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "''' \n",
    "Yellow Line: This represents the median of the response times. \n",
    "The median is the middle value when the data are arranged in order, \n",
    "providing a good indicator of the typical response time by cutting the data set in half.\n",
    "\n",
    "Purple Dashed Line: This represents the mean (average) of the response times. \n",
    "The mean is calculated by adding all response times and dividing by the number of response times. \n",
    "This gives a sense of the central tendency of the data but can be influenced by outliers.\n",
    "\n",
    "Using both in the plot allows users to quickly assess the skewness of the data:\n",
    "\n",
    "If the mean and median are close together, the data are more symmetrically distributed.\n",
    "If the mean is higher than the median, the data might be right-skewed, \n",
    "indicating that there are some unusually high response times pulling the average up.\n",
    "These visual indicators are crucial for understanding the overall performance characteristics of the API under test, \n",
    "especially in the context of volume testing where response consistency is key.\n",
    "'''\n",
    "def plot_response_times_across_users(total_response_times):\n",
    "    num_users = len(total_response_times)\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    boxprops = dict(linestyle='-', linewidth=2, color='blue')\n",
    "    flierprops = dict(marker='o', color='red', alpha=0.5)\n",
    "    medianprops = dict(linestyle='-', linewidth=2, color='yellow')\n",
    "\n",
    "    bp = ax.boxplot(total_response_times, patch_artist=True, labels=[f\"User {i}\" for i in range(1, num_users + 1)],\n",
    "                    boxprops=boxprops, flierprops=flierprops, medianprops=medianprops,\n",
    "                    showmeans=True, meanline=True, meanprops=dict(linestyle='--', linewidth=2, color='purple'))\n",
    "\n",
    "    for box in bp['boxes']:\n",
    "        box.set(facecolor = 'lightblue')\n",
    "\n",
    "    ax.set_title('Response Times Across All Users')\n",
    "    ax.set_xlabel('User Index')\n",
    "    ax.set_ylabel('Response Time (s)')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   run_test()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
