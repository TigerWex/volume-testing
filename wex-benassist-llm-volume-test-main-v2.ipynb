{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684202.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684204.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684206.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684208.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684210.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684212.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684214.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684216.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684218.\n",
      "An error occurred during authentication: 400 Client Error: Bad Request for url: https://dv-id.mybenefitexpress.com/connect/token\n",
      "Error: Invalid Bearer token for user T_09684220.\n",
      "No valid tokens retrieved. Exiting...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\W513032\\source\\repos\\volume testing\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "import certifi\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display, clear_output\n",
    "from threading import Lock\n",
    "from datetime import datetime\n",
    "from langchain_community.llms import Bedrock\n",
    "from langchain_aws import BedrockLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import sys\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "import urllib3\n",
    "import base64\n",
    "\n",
    "# suppress warnings are due to making HTTPS requests to localhost without verifying SSL certificates. \n",
    "# Suppress only the single InsecureRequestWarning from urllib3 needed\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Set the AWS profile and certificate bundle\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
    "\n",
    "# Configuration values\n",
    "auth_client_secret = \"14DA6952-20F7-46EC-9342-F3F4BCF8EC1A\"\n",
    "auth_url = \"https://dv-id.mybenefitexpress.com/connect/token\"\n",
    "auth_scope = \"externalidentityprovider\"\n",
    "\n",
    "def validate_file(file_path):\n",
    "    \"\"\"\n",
    "    Validates the uploaded file to ensure it can be read as an Excel file.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, path to the file to be validated\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple (bool, int): True if the file is valid, and the number of rows in the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return True, df.shape[0]\n",
    "    except Exception as e:\n",
    "        return False, 0\n",
    "\n",
    "def validate_token(token):\n",
    "    \"\"\"\n",
    "    Validates the Bearer token by making a test API call.\n",
    "    \n",
    "    Parameters:\n",
    "    - token: str, the Bearer token\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the token is valid, False otherwise\n",
    "    \"\"\"\n",
    "    url = 'https://localhost:8443/v1.0/benefitassistant/Session'\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'Authorization': f'Bearer {token}'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, verify=False)  # verify=False for local testing, remove in production\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False\n",
    "\n",
    "def retrieve_token(client_id, client_secret, auth_url, auth_scope):\n",
    "    \"\"\"\n",
    "    Retrieve an authentication token using client credentials.\n",
    "    \n",
    "    Parameters:\n",
    "    - client_id: str, the client ID\n",
    "    - client_secret: str, the client secret\n",
    "    - auth_url: str, the URL to get the token\n",
    "    - auth_scope: str, the scope for authentication\n",
    "    \n",
    "    Returns:\n",
    "    - token: str, the authentication token\n",
    "    \"\"\"\n",
    "    # Check if the token is already set and not expired (pseudo-code)\n",
    "    # if is_token_already_set_and_not_expired():\n",
    "    #     return last_token_generated\n",
    "\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"scope\": auth_scope,\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret\n",
    "    }\n",
    "    \n",
    "    # Encode client_id and client_secret\n",
    "    encoded_auth_pair = base64.b64encode(f\"{client_id}:{client_secret}\".encode()).decode()\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {encoded_auth_pair}\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(auth_url, data=data, headers=headers)\n",
    "        response.raise_for_status()  # Raises a HTTPError if the response code was unsuccessful\n",
    "\n",
    "        token_data = response.json()\n",
    "        token_generated = token_data['access_token']\n",
    "\n",
    "        return token_generated\n",
    "    except requests.RequestException as ex:\n",
    "        # Log the error\n",
    "        print(f\"An error occurred during authentication: {ex}\")\n",
    "        return \"\"\n",
    "\n",
    "def refresh_bedrock_client():\n",
    "    \"\"\"\n",
    "    Refreshes the Bedrock client with new credentials.\n",
    "    \n",
    "    Returns:\n",
    "    - bedrock_client: boto3 client, refreshed Bedrock client, or None if an error occurs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session = boto3.Session(profile_name=os.environ[\"AWS_PROFILE\"])\n",
    "        credentials = session.get_credentials()\n",
    "        credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "        bedrock_client = boto3.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            region_name=\"us-east-1\",\n",
    "            aws_access_key_id=credentials.access_key,\n",
    "            aws_secret_access_key=credentials.secret_key,\n",
    "            aws_session_token=credentials.token\n",
    "        )\n",
    "        return bedrock_client\n",
    "    except (NoCredentialsError, PartialCredentialsError) as e:\n",
    "        print(f\"Error refreshing AWS credentials: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def chat(question, token):\n",
    "    \"\"\"\n",
    "    Sends a question to the API and returns the response.\n",
    "    \n",
    "    Parameters:\n",
    "    - question: str, the question to be sent\n",
    "    - token: str, the authorization token for the API\n",
    "    \n",
    "    Returns:\n",
    "    - response: dict, the response from the API\n",
    "    \"\"\"\n",
    "    url = f'https://localhost:8443/v1.0/benefitassistant/Assistant/llm-response?question={question}'\n",
    "    headers = {\n",
    "        'accept': '*/*',\n",
    "        'Authorization': f'Bearer {token}'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, verify=False)  # verify=False for local testing, remove in production\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def simulate_user_questions(user_id, questions, question_ids, user_progress, user_time, response_times, avg_response_times, error_log, lock, results, token, start_time):\n",
    "    \"\"\"\n",
    "    Simulates a user asking questions and updates the progress.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: str, ID of the user\n",
    "    - questions: list, list of questions to ask\n",
    "    - question_ids: list, list of question IDs corresponding to the questions\n",
    "    - user_progress: dict, dictionary to store user progress\n",
    "    - user_time: dict, dictionary to store time taken by the user\n",
    "    - response_times: list, list of response times for each question\n",
    "    - avg_response_times: list, list of average response times for each question\n",
    "    - error_log: list, list to store error messages\n",
    "    - lock: threading.Lock, lock to synchronize access to shared resources\n",
    "    - results: list, list to store results for the Excel file\n",
    "    - token: str, the authorization token for the API\n",
    "    - start_time: float, the start time of the first question submission\n",
    "    \"\"\"\n",
    "    combined = list(zip(question_ids, questions))\n",
    "    random.shuffle(combined)\n",
    "    for question_id, question in combined:\n",
    "        try:\n",
    "            start_time_question = time.time()\n",
    "            response = chat(question, token)\n",
    "            end_time_question = time.time()\n",
    "            time_taken = end_time_question - start_time_question\n",
    "            user_time[user_id] += time_taken\n",
    "            response_times.append(time_taken)\n",
    "            avg_response_times.append(sum(response_times) / len(response_times))\n",
    "            \n",
    "            if \"error\" in response:\n",
    "                raise Exception(response[\"error\"])\n",
    "            \n",
    "            answer = response.get(\"answer\", \"\")\n",
    "            user_progress[user_id][\"answered\"] += 1\n",
    "            results.append([user_id, question, answer, \"\"])\n",
    "        except Exception as e:\n",
    "            error_info = f\"Error occurred for user {user_id}, question ID {question_id}, question: {question}. Error: {str(e)}\"\n",
    "            error_log.append(error_info)\n",
    "            user_progress[user_id][\"error\"] += 1\n",
    "            results.append([user_id, question, \"\", str(e)])\n",
    "\n",
    "        with lock:\n",
    "            update_plot(user_progress, user_time, response_times, avg_response_times, error_log, start_time)\n",
    "\n",
    "def update_plot(user_progress, user_time, response_times, avg_response_times, error_log, start_time):\n",
    "    \"\"\"\n",
    "    Updates the plot showing the progress of users and other metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_progress: dict, dictionary containing progress of users\n",
    "    - user_time: dict, dictionary containing time taken by users\n",
    "    - response_times: list, list of response times\n",
    "    - avg_response_times: list, list of average response times\n",
    "    - error_log: list, list of error messages\n",
    "    - start_time: float, the start time of the first question submission\n",
    "    \"\"\"\n",
    "    progress_df = pd.DataFrame(user_progress).T\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 15))\n",
    "\n",
    "    # Adjust layout to add space between the plots\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    # Plot progress of answered questions for each user\n",
    "    progress_df.plot(kind='bar', stacked=True, color=['green', 'red'], ax=axes[0])\n",
    "    axes[0].set_xlabel('User ID')\n",
    "    axes[0].set_ylabel('Number of Questions')\n",
    "    axes[0].set_title('Progress of Answered Questions for Each User')\n",
    "    axes[0].yaxis.get_major_locator().set_params(integer=True)\n",
    "\n",
    "    # Annotate the bars with the time taken\n",
    "    for p in axes[0].patches:\n",
    "        width, height = p.get_width(), p.get_height()\n",
    "        if height > 0:\n",
    "            x, y = p.get_xy()\n",
    "            user_id = progress_df.index[int(x + width / 2)]\n",
    "            if user_progress[user_id][\"answered\"] > 0:  # Annotate only once per user\n",
    "                time_text = f\"{user_time[user_id] / 60:.2f} min\"\n",
    "                axes[0].annotate(time_text, (x + width / 2, height), \n",
    "                                 ha='center', va='bottom', fontsize=10, color='black', fontweight='bold')\n",
    "\n",
    "    # Calculate total elapsed time\n",
    "    total_time_taken = (time.time() - start_time) / 60  # in minutes\n",
    "\n",
    "    # Display number of errors, successful answers, and total time taken\n",
    "    total_errors = sum(user['error'] for user in user_progress.values())\n",
    "    total_successes = sum(user['answered'] for user in user_progress.values())\n",
    "    textstr = f'Total Errors: {total_errors}\\nTotal Successful Answers: {total_successes}\\nTotal Time Taken: {total_time_taken:.2f} min'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    axes[0].text(0.05, 0.95, textstr, transform=axes[0].transAxes, fontsize=12,\n",
    "                 verticalalignment='top', bbox=props)\n",
    "\n",
    "    # Plot response times and average response times\n",
    "    axes[1].plot(response_times, label='Response Time', color='orange')\n",
    "    axes[1].plot(avg_response_times, label='Average Response Time', linestyle='--', color='blue')\n",
    "    axes[1].set_xlabel('Request Number')\n",
    "    axes[1].set_ylabel('Response Time (s)')\n",
    "    axes[1].set_title('Response Times')\n",
    "    axes[1].legend()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "def analyze_results(user_count, question_count, total_successes, total_errors, total_time_taken, avg_response_times, response_times, error_log):\n",
    "    \"\"\"\n",
    "    Analyzes the volume test results using the Bedrock LLM.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_count: int, number of users\n",
    "    - question_count: int, number of questions\n",
    "    - total_successes: int, total successful answers\n",
    "    - total_errors: int, total errors\n",
    "    - total_time_taken: float, total time taken for the volume test\n",
    "    - avg_response_times: list, average response times for each request\n",
    "    - response_times: list, response times for each request\n",
    "    - error_log: list, list of error messages\n",
    "    \n",
    "    Returns:\n",
    "    - analysis: str, analysis provided by the LLM or an error message if the analysis fails\n",
    "    \"\"\"\n",
    "    results_summary = f\"\"\"\n",
    "    Volume Testing Results Summary:\n",
    "    - Number of users: {user_count}\n",
    "    - Number of questions: {question_count}\n",
    "    - Total Successful Answers: {total_successes}\n",
    "    - Total Errors: {total_errors}\n",
    "    - Total Time Taken: {total_time_taken:.2f} minutes\n",
    "    - Average Response Time: {sum(avg_response_times) / len(avg_response_times):.2f} seconds\n",
    "    - Maximum Response Time: {max(response_times):.2f} seconds\n",
    "    - Minimum Response Time: {min(response_times):.2f} seconds\n",
    "    \n",
    "    Error Log:\n",
    "    {error_log}\n",
    "    \"\"\"\n",
    "    \n",
    "    question = f\"\"\"\n",
    "    We are testing an API. Please analyze the following volume test results and provide insights on what is good, what problems exist, and how to improve performance if there are any issues.\n",
    "    \n",
    "    {results_summary}\n",
    "    \"\"\"\n",
    "    \n",
    "    global bedrock_client  # Ensure we use the global bedrock_client\n",
    "    llm = BedrockLLM(\n",
    "        model_id=model_id,\n",
    "        client=bedrock_client,\n",
    "        model_kwargs={\"max_gen_len\": 512, \"temperature\": 0.5}\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        bedrock_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        response = bedrock_chain({'question': question})\n",
    "        return response['text']\n",
    "    except Exception as e:\n",
    "        if \"ExpiredTokenException\" in str(e):\n",
    "            print(\"Token expired. Refreshing token...\")\n",
    "            bedrock_client = refresh_bedrock_client()\n",
    "            if bedrock_client is None:\n",
    "                print(\"Failed to refresh token. Continuing without analysis.\")\n",
    "                return \"Failed to refresh token. Analysis not performed.\"\n",
    "            \n",
    "            llm = BedrockLLM(\n",
    "                model_id=model_id,\n",
    "                client=bedrock_client,\n",
    "                model_kwargs={\"max_gen_len\": 512, \"temperature\": 0.5}\n",
    "            )\n",
    "            bedrock_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "            try:\n",
    "                response = bedrock_chain({'question': question})\n",
    "                return response['text']\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during analysis after token refresh: {str(e)}\")\n",
    "                return f\"An error occurred during analysis after token refresh: {str(e)}\"\n",
    "        else:\n",
    "            print(f\"An error occurred during analysis: {str(e)}\")\n",
    "            return f\"An error occurred during analysis: {str(e)}\"\n",
    "\n",
    "# Placeholder for user input file paths\n",
    "users_file_path = \"wex-users.xlsx\"  # Replace with the actual path\n",
    "questions_file_path = \"wex-questions.xlsx\"  # Replace with the actual path\n",
    "\n",
    "# Load user IDs from the users file\n",
    "users = pd.read_excel(users_file_path)\n",
    "user_ids = users[\"user-id\"].tolist()\n",
    "\n",
    "# Initialize a dictionary to store tokens\n",
    "user_tokens = {}\n",
    "\n",
    "# Retrieve and validate tokens for each user\n",
    "for user_id in user_ids:\n",
    "    try:\n",
    "        token = retrieve_token(user_id, auth_client_secret, auth_url, auth_scope)\n",
    "        if validate_token(token):\n",
    "            user_tokens[user_id] = token\n",
    "        else:\n",
    "            print(f\"Error: Invalid Bearer token for user {user_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving token for user {user_id}: {str(e)}\")\n",
    "\n",
    "# Proceed with the volume test using the tokens\n",
    "if not user_tokens:\n",
    "    print(\"No valid tokens retrieved. Exiting...\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Validate the files\n",
    "is_users_valid, user_count = validate_file(users_file_path)\n",
    "is_questions_valid, question_count = validate_file(questions_file_path)\n",
    "\n",
    "error_log = []\n",
    "response_times = []\n",
    "avg_response_times = []\n",
    "results = []\n",
    "\n",
    "if is_users_valid and is_questions_valid:\n",
    "    users = pd.read_excel(users_file_path)\n",
    "    questions_df = pd.read_excel(questions_file_path)\n",
    "\n",
    "    if 'Question' not in questions_df.columns or 'question-id' not in questions_df.columns:\n",
    "        print(\"Error: The 'question-id' and/or 'Question' column is not found in the questions file.\")\n",
    "        print(f\"Available columns are: {questions_df.columns.tolist()}\")\n",
    "    elif 'user-id' not in users.columns:\n",
    "        print(\"Error: The 'user-id' column is not found in the users file.\")\n",
    "        print(f\"Available columns are: {users.columns.tolist()}\")\n",
    "    else:\n",
    "        questions = questions_df[\"Question\"].tolist()\n",
    "        question_ids = questions_df[\"question-id\"].tolist()\n",
    "        user_ids = users[\"user-id\"].tolist()\n",
    "\n",
    "        print(f\"Number of user records: {user_count}\")\n",
    "        print(f\"Number of questions: {question_count}\")\n",
    "\n",
    "        user_progress = {user_id: {\"answered\": 0, \"error\": 0} for user_id in user_ids}\n",
    "        user_time = {user_id: 0 for user_id in user_ids}\n",
    "        lock = Lock()\n",
    "\n",
    "        bedrock_client = boto3.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            region_name=\"us-east-1\"\n",
    "        )\n",
    "\n",
    "        llm = BedrockLLM(\n",
    "            model_id=model_id,\n",
    "            client=bedrock_client,\n",
    "            model_kwargs={\"max_gen_len\": 512, \"temperature\": 0.5}\n",
    "        )\n",
    "\n",
    "        start_time = time.time()  # Capture the start time\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=len(user_ids)) as executor:\n",
    "            futures = []\n",
    "            for user_id in user_ids:\n",
    "                token = user_tokens.get(user_id)\n",
    "                if token:\n",
    "                    futures.append(executor.submit(simulate_user_questions, user_id, questions, question_ids, user_progress, user_time, response_times, avg_response_times, error_log, lock, results, token, start_time))\n",
    "                    time.sleep(5)\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                future.result()\n",
    "\n",
    "        total_time_taken = (time.time() - start_time) / 60  # Calculate the total elapsed time\n",
    "\n",
    "        print(f\"Volume testing completed with {user_count} users and {question_count} questions.\")\n",
    "        if error_log:\n",
    "            print(\"Errors occurred during volume testing. Here are the details:\")\n",
    "            for error in error_log:\n",
    "                print(error)\n",
    "\n",
    "        try:\n",
    "            # Analyze the results using the LLM\n",
    "            total_successes = sum(user['answered'] for user in user_progress.values())\n",
    "            total_errors = sum(user['error'] for user in user_progress.values())\n",
    "            analysis = analyze_results(len(user_ids), len(questions), total_successes, total_errors, total_time_taken, avg_response_times, response_times, error_log)\n",
    "            print(\"\\nLLM Analysis and Recommendations:\\n\")\n",
    "            print(analysis)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during analysis: {str(e)}\")\n",
    "\n",
    "        # Save results to an Excel file\n",
    "        results_df = pd.DataFrame(results, columns=['user-id', 'question', 'answer', 'error'])\n",
    "        timestamp = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "        results_df.to_excel(f'volume-test-run-{timestamp}.xlsx', index=False)\n",
    "        print(f\"Results saved to volume-test-run-{timestamp}.xlsx\")\n",
    "else:\n",
    "    print(\"One or both of the uploaded files are not valid Excel files.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
