{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 153\u001b[0m\n\u001b[0;32m    148\u001b[0m lock \u001b[38;5;241m=\u001b[39m Lock()\n\u001b[0;32m    150\u001b[0m bedrock_client \u001b[38;5;241m=\u001b[39m initialize_bedrock_client()\n\u001b[0;32m    152\u001b[0m llm \u001b[38;5;241m=\u001b[39m BedrockLLM(\n\u001b[1;32m--> 153\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_id\u001b[49m,\n\u001b[0;32m    154\u001b[0m     client\u001b[38;5;241m=\u001b[39mbedrock_client,\n\u001b[0;32m    155\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_gen_len\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m}\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39muser_count) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m    159\u001b[0m     futures \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_id' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import random\n",
    "import boto3\n",
    "from langchain_community.llms import Bedrock\n",
    "from langchain_aws import BedrockLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import time\n",
    "import certifi\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import display, clear_output\n",
    "from threading import Lock\n",
    "\n",
    "# Set the AWS profile and certificate bundle\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
    "\n",
    "# Set the model ID\n",
    "model_id = \"meta.llama3-8b-instruct-v1:0\"\n",
    "\n",
    "# Create a temporary directory for storing the uploaded files\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "def validate_file(file_path):\n",
    "    \"\"\"\n",
    "    Validates the uploaded file to ensure it can be read as an Excel file.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: str, path to the file to be validated\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple (bool, int): True if the file is valid, and the number of rows in the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        return True, df.shape[0]\n",
    "    except Exception as e:\n",
    "        return False, 0\n",
    "\n",
    "def initialize_bedrock_client():\n",
    "    \"\"\"\n",
    "    Initializes the Bedrock client.\n",
    "    \n",
    "    Returns:\n",
    "    - bedrock_client: boto3 client, initialized Bedrock client\n",
    "    \"\"\"\n",
    "    return boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=\"us-east-1\"\n",
    "    )\n",
    "\n",
    "def chat(question):\n",
    "    \"\"\"\n",
    "    Sends a question to the Bedrock LLM and returns the response.\n",
    "    \n",
    "    Parameters:\n",
    "    - question: str, the question to be sent\n",
    "    \n",
    "    Returns:\n",
    "    - response: dict, the response from the LLM\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"{question}\"\n",
    "    )\n",
    "\n",
    "    bedrock_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    response = bedrock_chain({'question': question})\n",
    "    return response\n",
    "\n",
    "def simulate_user_questions(user_id, questions, user_progress, user_time, lock):\n",
    "    \"\"\"\n",
    "    Simulates a user asking questions and updates the progress.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: int, ID of the user\n",
    "    - questions: list, list of questions to ask\n",
    "    - user_progress: dict, dictionary to store user progress\n",
    "    - user_time: dict, dictionary to store time taken by the user\n",
    "    - lock: threading.Lock, lock to synchronize access to shared resources\n",
    "    \"\"\"\n",
    "    random.shuffle(questions)\n",
    "    for question in questions:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = chat(question)\n",
    "            answer = response[\"text\"]\n",
    "            end_time = time.time()\n",
    "            time_taken = end_time - start_time\n",
    "            user_time[user_id] += time_taken\n",
    "            user_progress[user_id][\"answered\"] += 1\n",
    "        except Exception as e:\n",
    "            error_info = f\"Error occurred for user {user_id} question: {question}. Error: {str(e)}\"\n",
    "            error_log.append(error_info)\n",
    "            user_progress[user_id][\"error\"] += 1\n",
    "\n",
    "        with lock:\n",
    "            update_plot(user_progress, user_time)\n",
    "\n",
    "def update_plot(user_progress, user_time):\n",
    "    \"\"\"\n",
    "    Updates the plot showing the progress of users.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_progress: dict, dictionary containing progress of users\n",
    "    - user_time: dict, dictionary containing time taken by users\n",
    "    \"\"\"\n",
    "    progress_df = pd.DataFrame(user_progress).T\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    progress_df.plot(kind='bar', stacked=True, color=['green', 'red'], ax=ax)\n",
    "    ax.set_xlabel('User ID')\n",
    "    ax.set_ylabel('Number of Questions')\n",
    "    ax.set_title('Progress of Answered Questions for Each User')\n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        user_id = int(p.get_x() + p.get_width() / 2)\n",
    "        time_text = f\"time: {user_time[user_id] / 60:.2f} min\"\n",
    "        ax.annotate(time_text, (p.get_x() + p.get_width() / 2, p.get_height() + 0.5), \n",
    "                    ha='center', va='center', fontsize=10, color='black', fontweight='bold')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Placeholder for user input file paths\n",
    "users_file_path = \"users.xlsx\"  # Replace with the actual path\n",
    "questions_file_path = \"questions.xlsx\"  # Replace with the actual path\n",
    "\n",
    "# Validate the files\n",
    "is_users_valid, user_count = validate_file(users_file_path)\n",
    "is_questions_valid, question_count = validate_file(questions_file_path)\n",
    "\n",
    "error_log = []\n",
    "\n",
    "if is_users_valid and is_questions_valid:\n",
    "    users = pd.read_excel(users_file_path)\n",
    "    questions_df = pd.read_excel(questions_file_path)\n",
    "\n",
    "    if 'Question' not in questions_df.columns:\n",
    "        print(\"Error: The 'Question' column is not found in the questions file.\")\n",
    "        print(f\"Available columns are: {questions_df.columns.tolist()}\")\n",
    "    else:\n",
    "        questions = questions_df[\"Question\"].tolist()\n",
    "\n",
    "        user_progress = {user_id: {\"answered\": 0, \"error\": 0} for user_id in users.index}\n",
    "        user_time = {user_id: 0 for user_id in users.index}\n",
    "        lock = Lock()\n",
    "\n",
    "        bedrock_client = initialize_bedrock_client()\n",
    "\n",
    "        llm = BedrockLLM(\n",
    "            model_id=model_id,\n",
    "            client=bedrock_client,\n",
    "            model_kwargs={\"max_gen_len\": 512, \"temperature\": 0.5}\n",
    "        )\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=user_count) as executor:\n",
    "            futures = []\n",
    "            for user_id in users.index:\n",
    "                futures.append(executor.submit(simulate_user_questions, user_id, questions, user_progress, user_time, lock))\n",
    "                time.sleep(5)\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                future.result()\n",
    "\n",
    "        print(f\"Volume testing completed with {user_count} users and {question_count} questions.\")\n",
    "        if error_log:\n",
    "            print(\"Errors occurred during volume testing. Here are the details:\")\n",
    "            for error in error_log:\n",
    "                print(error)\n",
    "else:\n",
    "    print(\"One or both of the uploaded files are not valid Excel files.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
